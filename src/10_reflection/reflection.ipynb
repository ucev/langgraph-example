{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评：整个过程其实就是\n",
    "1. 产出\n",
    "2. 对产出进行评价，提出改进计划\n",
    "3. 将产出和评价作为历史纪录，重复`1`，直到达到结束条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import './../../loadenv.mjs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { getModel } from './../../utils.mjs'\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\n",
    "        \"system\",\n",
    "        `You are an essay assistant tasked with writing excellent 5-paragraph essays.\n",
    "Generate the best essay possible for the user's request.  \n",
    "If the user provides critique, respond with a revised version of your previous attempts.`,\n",
    "    ],\n",
    "    new MessagesPlaceholder('messages'),\n",
    "])\n",
    "const llm = getModel()\n",
    "const essayGenerationChain = prompt.pipe(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { AIMessage, BaseMessage, HumanMessage } from '@langchain/core/messages'\n",
    "\n",
    "let essay = ''\n",
    "const request = new HumanMessage({\n",
    "    content: 'Write an essay on why the little prince is relevant in modern childhood',\n",
    "})\n",
    "// for await (\n",
    "//     const chunk of await essayGenerationChain.stream({\n",
    "//         messages: [request],\n",
    "//     })\n",
    "// ) {\n",
    "//     essay += chunk.content\n",
    "// }\n",
    "// essay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const reflectionPrompt = ChatPromptTemplate.fromMessages([\n",
    "    [\n",
    "        'system',\n",
    "        `You are a teacher grading an essay submission.\n",
    "Generate critique and recommendations for the user's submission.\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.`\n",
    "    ],\n",
    "    new MessagesPlaceholder('messages'),\n",
    "])\n",
    "const reflect = reflectionPrompt.pipe(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let reflection = ''\n",
    "// for await (\n",
    "//     const chunk of await reflect.stream({\n",
    "//         messages: [\n",
    "//             request,\n",
    "//             new HumanMessage({ content: essay }),\n",
    "//         ]\n",
    "//     })\n",
    "// ) {\n",
    "//     reflection += chunk.content\n",
    "// }\n",
    "// reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let stream = await essayGenerationChain.stream({\n",
    "//     messages: [\n",
    "//         request,\n",
    "//         new AIMessage({ content: essay }),\n",
    "//         new HumanMessage({ content: reflection }),\n",
    "//     ]\n",
    "// })\n",
    "// for await (const chunk of stream) {\n",
    "//     console.log(chunk.content)\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, MemorySaver, StateGraph, START, Annotation } from '@langchain/langgraph'\n",
    "\n",
    "const State = Annotation.Root({\n",
    "    messages: Annotation<BaseMessage[]>({\n",
    "        reducer: (x, y) => x.concat(y),\n",
    "    })\n",
    "})\n",
    "\n",
    "const generationNode = async (state: typeof State.State) => {\n",
    "    const { messages } = state\n",
    "    return {\n",
    "        messages: [await essayGenerationChain.invoke({ messages })],\n",
    "    }\n",
    "}\n",
    "\n",
    "const reflectionNode = async (state: typeof State.State) => {\n",
    "    const { messages } = state\n",
    "    const clsMap: { [key: string]: new (content: string) => BaseMessage } = {\n",
    "        ai: HumanMessage,\n",
    "        human: AIMessage,\n",
    "    }\n",
    "    const translated = [\n",
    "        messages[0],\n",
    "        ...messages.slice(1).map(msg => new clsMap[msg._getType()](msg.content.toString())),\n",
    "    ]\n",
    "    const res = await reflect.invoke({ messages: translated })\n",
    "    return {\n",
    "        messages: [new HumanMessage({ content: res.content })],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const workflow = new StateGraph(State)\n",
    "    .addNode('generate', generationNode)\n",
    "    .addNode('reflect', reflectionNode)\n",
    "    .addEdge(START, 'generate')\n",
    "\n",
    "const shouldContinue = (state: typeof State.State) => {\n",
    "    const { messages } = state\n",
    "    if (messages.length > 6) {\n",
    "        return END\n",
    "    }\n",
    "    return 'reflect'\n",
    "}\n",
    "\n",
    "workflow\n",
    "    .addConditionalEdges('generate', shouldContinue)\n",
    "    .addEdge('reflect', 'generate')\n",
    "\n",
    "const app = workflow.compile({ checkpointer: new MemorySaver() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { printGraph } from './../../utils.mjs'\n",
    "await printGraph(app.getGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const checkpointConfig = { configurable: { thread_id: 'my-thread' }}\n",
    "\n",
    "let stream = await app.stream(\n",
    "    {\n",
    "        messages: [\n",
    "            new HumanMessage({\n",
    "                content: 'Generate an essay on the topicality of The Little Prince and its message in modern life',\n",
    "            })\n",
    "        ]\n",
    "    },\n",
    "    checkpointConfig,\n",
    ")\n",
    "\n",
    "for await (const event of stream) {\n",
    "    for (const [key, _value] of Object.entries(event)) {\n",
    "        console.log(`Event: ${key}`)\n",
    "        console.log('\\n------\\n')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const snapshot = await app.getState(checkpointConfig)\n",
    "console.log(\n",
    "    snapshot.values.messages\n",
    "        .map((msg: BaseMessage) => msg.content)\n",
    "        .join('\\n\\n\\n------------------\\n\\n\\n')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
