{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import './../../loadenv.mjs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "import { StructuredTool } from '@langchain/core/tools'\n",
    "import { convertToOpenAITool } from '@langchain/core/utils/function_calling'\n",
    "import { Runnable } from '@langchain/core/runnables'\n",
    "import { getModel } from './../../utils.mjs'\n",
    "import { ChatOpenAI } from '@langchain/openai'\n",
    "\n",
    "async function createAgent({\n",
    "    llm,\n",
    "    tools,\n",
    "    systemMessage\n",
    "}: {\n",
    "    llm: ChatOpenAI;\n",
    "    tools: StructuredTool[];\n",
    "    systemMessage: string;\n",
    "}): Promise<Runnable> {\n",
    "    const toolNames = tools.map(tool => tool.name).join(', ')\n",
    "    const formattedTools = tools.map(t => convertToOpenAITool(t))\n",
    "\n",
    "    let prompt = ChatPromptTemplate.fromMessages([\n",
    "        [\n",
    "            \"system\",\n",
    "            \"You are a helpful AI assistant, collaborating with other assistants.\" +\n",
    "            \" Use the provided tools to progress towards answering the question.\" +\n",
    "            \" If you are unable to fully answer, that's OK, another assistant with different tools \" +\n",
    "            \" will help where you left off. Execute what you can to make progress.\" +\n",
    "            // \" If you or any of the other assistants have the final answer or deliverable,\" +\n",
    "            // \" prefix your response with FINAL ANSWER so the team knows to stop.\" +\n",
    "            /// 根据豆包的功能，对提示词进行修改\n",
    "            \" Only if you have all ready displayed a bar chart to user, \" +\n",
    "            \" can you prefix your response with FINAL ANSWER so the team knows to stop.\" +\n",
    "\n",
    "            \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "        ],\n",
    "        new MessagesPlaceholder(\"messages\"),\n",
    "    ])\n",
    "    prompt = await prompt.partial({\n",
    "        system_message: systemMessage,\n",
    "        tool_names: toolNames,\n",
    "    })\n",
    "\n",
    "    return prompt.pipe(llm.bind({ tools: formattedTools }))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { BaseMessage } from '@langchain/core/messages'\n",
    "import { Annotation } from '@langchain/langgraph'\n",
    "\n",
    "const AgentState = Annotation.Root({\n",
    "    messages: Annotation<BaseMessage[]>({\n",
    "        reducer: (x, y) => x.concat(y),\n",
    "    }),\n",
    "    sender: Annotation<string>({\n",
    "        reducer: (x, y) => y ?? x ?? 'user',\n",
    "        default: () => 'user',\n",
    "    }),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TavilySearchResults } from '@langchain/community/tools/tavily_search'\n",
    "import { tool } from '@langchain/core/tools'\n",
    "import * as d3 from 'd3'\n",
    "import { createCanvas } from 'canvas'\n",
    "import { z } from 'zod'\n",
    "import { displayImage } from '../../utils.mjs'\n",
    "\n",
    "const chartTool = tool(\n",
    "    async ({ data }) => {\n",
    "        const width = 500\n",
    "        const height = 500\n",
    "        const margin = { top: 20, right: 30, bottom: 30, left: 40 }\n",
    "        \n",
    "        const canvas = createCanvas(width, height)\n",
    "        const ctx = canvas.getContext('2d')\n",
    "\n",
    "        const x = d3\n",
    "            .scaleBand()\n",
    "            .domain(data.map(d => d.label))\n",
    "            .range([margin.left, width - margin.right])\n",
    "            .padding(0.1)\n",
    "        const y = d3\n",
    "            .scaleLinear()\n",
    "            .domain([0, d3.max(data, (d: any) => d.value) ?? 0])\n",
    "            .nice()\n",
    "            .range([height - margin.bottom, margin.top])\n",
    "        \n",
    "        const colorPalette = [\n",
    "            \"#e6194B\",\n",
    "            \"#3cb44b\",\n",
    "            \"#ffe119\",\n",
    "            \"#4363d8\",\n",
    "            \"#f58231\",\n",
    "            \"#911eb4\",\n",
    "            \"#42d4f4\",\n",
    "            \"#f032e6\",\n",
    "            \"#bfef45\",\n",
    "            \"#fabebe\",\n",
    "        ]\n",
    "        data.forEach((d, idx) => {\n",
    "            ctx.fillStyle = colorPalette[idx % colorPalette.length]\n",
    "            ctx.fillRect(\n",
    "                x(d.label) ?? 0,\n",
    "                y(d.value),\n",
    "                x.bandwidth(),\n",
    "                height - margin.bottom - y(d.value),\n",
    "            )\n",
    "        })\n",
    "\n",
    "        ctx.beginPath()\n",
    "        ctx.strokeStyle = 'black'\n",
    "        ctx.moveTo(margin.left, height - margin.bottom)\n",
    "        ctx.lineTo(width - margin.right, height - margin.bottom)\n",
    "        ctx.stroke()\n",
    "\n",
    "        ctx.textAlign = 'center'\n",
    "        ctx.textBaseline = 'top'\n",
    "        x.domain().forEach((d: any) => {\n",
    "            const xCoord = (x(d) ?? 0) + x.bandwidth() / 2\n",
    "            ctx.fillText(d, xCoord, height - margin.bottom + 6)\n",
    "        })\n",
    "\n",
    "        ctx.beginPath()\n",
    "        ctx.moveTo(margin.left, height - margin.top)\n",
    "        ctx.lineTo(margin.left, height - margin.bottom)\n",
    "        ctx.stroke()\n",
    "\n",
    "        ctx.textAlign = 'right'\n",
    "        ctx.textBaseline = 'middle'\n",
    "        const ticks = y.ticks()\n",
    "        ticks.forEach((d: any) => {\n",
    "            const yCoord = y(d)\n",
    "            ctx.moveTo(margin.left, yCoord)\n",
    "            ctx.lineTo(margin.left - 6, yCoord)\n",
    "            ctx.stroke()\n",
    "            ctx.fillText(d.toString(), margin.left - 8, yCoord)\n",
    "        })\n",
    "        console.log('+++ show canvas png')\n",
    "        const buffer = canvas.toBuffer()\n",
    "        // 这个方法很重要\n",
    "        await displayImage(buffer)\n",
    "        return 'Chart has been generated and displayed to the user!'\n",
    "    },\n",
    "    {\n",
    "        name: 'generate_bar_chart',\n",
    "        description: 'Generates a bar chart from an array of data points using D3.js and displays it for the user.',\n",
    "        schema: z.object({\n",
    "            data: z\n",
    "                .object({\n",
    "                    label: z.string(),\n",
    "                    value: z.number(),\n",
    "                }).array(),\n",
    "        })\n",
    "    }\n",
    ")\n",
    "\n",
    "const tavilyTool = new TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define agent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessage } from '@langchain/core/messages'\n",
    "import type { RunnableConfig } from '@langchain/core/runnables'\n",
    "\n",
    "async function runAgentNode(props: {\n",
    "    state: typeof AgentState.State;\n",
    "    agent: Runnable;\n",
    "    name: string;\n",
    "    config?: RunnableConfig;\n",
    "}) {\n",
    "    const { state, agent, name, config } = props\n",
    "    let result = await agent.invoke(state, config)\n",
    "    if (!result?.tool_calls || result.tool_calls.length === 0) {\n",
    "        result = new HumanMessage({ ...result, name, })\n",
    "    }\n",
    "    return {\n",
    "        messages: [result],\n",
    "        sender: name,\n",
    "    }\n",
    "}\n",
    "\n",
    "const llm = getModel()\n",
    "\n",
    "const researchAgent = await createAgent({\n",
    "    llm,\n",
    "    tools: [tavilyTool],\n",
    "    systemMessage: 'You should provide accurate data for the chart generator to use.\\nLet\\'s think step by step.'\n",
    "})\n",
    "\n",
    "async function researchNode(\n",
    "    state: typeof AgentState.State,\n",
    "    config?: RunnableConfig,\n",
    ") {\n",
    "    return runAgentNode({\n",
    "        state,\n",
    "        agent: researchAgent,\n",
    "        name: 'Researcher',\n",
    "        config,\n",
    "    })\n",
    "}\n",
    "\n",
    "const chartAgent = await createAgent({\n",
    "    llm,\n",
    "    tools: [chartTool],\n",
    "    systemMessage: 'Any charts you display will be visible by the user.'\n",
    "})\n",
    "\n",
    "async function chartNode(state: typeof AgentState.State) {\n",
    "    return runAgentNode({\n",
    "        state,\n",
    "        agent: chartAgent,\n",
    "        name: 'ChartGenerator',\n",
    "    })\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "// const researchResults = await researchNode({\n",
    "//     messages: [new HumanMessage('Research the US primaries in 2024')],\n",
    "//     sender: 'User',\n",
    "// })\n",
    "\n",
    "// researchResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define tool node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ToolNode } from '@langchain/langgraph/prebuilt'\n",
    "\n",
    "const tools = [tavilyTool, chartTool]\n",
    "const toolNode = new ToolNode<typeof AgentState.State>(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "// await toolNode.invoke(researchResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define edge logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { AIMessage } from '@langchain/core/messages'\n",
    "\n",
    "function router(state: typeof AgentState.State) {\n",
    "    const messages = state.messages\n",
    "    const lastMessage = messages[messages.length - 1] as AIMessage\n",
    "    if (lastMessage?.tool_calls && lastMessage.tool_calls.length > 0) {\n",
    "        return 'call_tool'\n",
    "    }\n",
    "    if (typeof lastMessage.content === 'string' && lastMessage.content.startsWith('FINAL ANSWER')) {\n",
    "        return 'end'\n",
    "    }\n",
    "    return 'continue'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, START, StateGraph } from '@langchain/langgraph'\n",
    "\n",
    "const workflow = new StateGraph(AgentState)\n",
    "    .addNode('Researcher', researchNode)\n",
    "    .addNode('ChartGenerator', chartNode)\n",
    "    .addNode('call_tool', toolNode)\n",
    "\n",
    "workflow.addConditionalEdges(\n",
    "    'Researcher',\n",
    "    router,\n",
    "    {\n",
    "        continue: 'ChartGenerator',\n",
    "        call_tool: 'call_tool',\n",
    "        end: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.addConditionalEdges(\n",
    "    'ChartGenerator',\n",
    "    router,\n",
    "    {\n",
    "        continue: 'Researcher',\n",
    "        call_tool: 'call_tool',\n",
    "        end: END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.addConditionalEdges(\n",
    "    'call_tool',\n",
    "    x => x.sender,\n",
    "    {\n",
    "        Researcher: 'Researcher',\n",
    "        ChartGenerator: 'ChartGenerator',\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.addEdge(START, 'Researcher')\n",
    "const graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const representation = graph.getGraph()\n",
    "const image = await representation.drawMermaidPng()\n",
    "const arrayBuffer = await image.arrayBuffer()\n",
    "\n",
    "Deno.jupyter.image(new Uint8Array(arrayBuffer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const streamResults = await graph.stream(\n",
    "    {\n",
    "        messages: [\n",
    "            new HumanMessage({\n",
    "                content: 'Generate a bar chart of the US gdp over the past 3 years.'\n",
    "            }),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        recursionLimit: 150,\n",
    "    }\n",
    ")\n",
    "\n",
    "const prettifyOutput = (output: Record<string, any>) => {\n",
    "    const keys = Object.keys(output)\n",
    "    const firstItem = output[keys[0]]\n",
    "\n",
    "    if ('messages' in firstItem && Array.isArray(firstItem.messages)) {\n",
    "        const lastMessage = firstItem.messages[firstItem.messages.length - 1]\n",
    "        console.dir({\n",
    "            type: lastMessage._getType(),\n",
    "            content: lastMessage.content,\n",
    "            tool_calls: lastMessage.tool_calls,\n",
    "        })\n",
    "    }\n",
    "    if ('sender' in firstItem) {\n",
    "        console.log({\n",
    "            sender: firstItem.sender,\n",
    "        })\n",
    "    }\n",
    "}\n",
    "\n",
    "for await (const output of await streamResults) {\n",
    "    if (!output?.__end__) {\n",
    "        prettifyOutput(output)\n",
    "        console.log('----')\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
