{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import '../../loadenv.mjs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { END, Annotation } from '@langchain/langgraph'\n",
    "import { BaseMessage } from '@langchain/core/messages'\n",
    "\n",
    "const AgentState = Annotation.Root({\n",
    "    messages: Annotation<BaseMessage[]>({\n",
    "        reducer: (x, y) => x.concat(y),\n",
    "        default: () => [],\n",
    "    }),\n",
    "    next: Annotation<string>({\n",
    "        reducer: (x, y) => y ?? x ?? END,\n",
    "        default: () => END,\n",
    "    })\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { chartTool } from './../../utils.mjs'\n",
    "import { TavilySearchResults } from '@langchain/community/tools/tavily_search'\n",
    "\n",
    "const tavilyTool = new TavilySearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Agent Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from 'zod'\n",
    "import { getModel } from './../../utils.mjs'\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts'\n",
    "import { AIMessage } from '@langchain/core/messages'\n",
    "\n",
    "const members = ['researcher', 'chart_generator'] as const\n",
    "const systemPrompt = \"You are a supervisor tasked with managing a conversation between the\" +\n",
    "  \" following workers: {members}. Given the following user request,\" +\n",
    "  \" respond with the worker to act next. Each worker will perform a\" +\n",
    "  \" task and respond with their results and status. When finished,\" +\n",
    "  \" respond with FINISH.\"\n",
    "const options = [END, ...members]\n",
    "\n",
    "const routingTool = {\n",
    "    name: 'route',\n",
    "    description: 'Select the next role.',\n",
    "    schema: z.object({\n",
    "        next: z.enum([END, ...members]),\n",
    "    })\n",
    "}\n",
    "\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    ['system', systemPrompt],\n",
    "    new MessagesPlaceholder('messages'),\n",
    "    [\n",
    "        'human',\n",
    "        'Given the conversation above, who should act next?' +\n",
    "        ' Or should we FINISH? Select one of: {options}',\n",
    "    ]\n",
    "])\n",
    "\n",
    "const formattedPrompt = await prompt.partial({\n",
    "    options: options.join(', '),\n",
    "    members: members.join(', '),\n",
    "})\n",
    "\n",
    "const llm = getModel()\n",
    "\n",
    "const supervisorChain = formattedPrompt\n",
    "    .pipe(llm.bindTools(\n",
    "        [routingTool],\n",
    "        {\n",
    "            tool_choice: 'route',\n",
    "        },\n",
    "    ))\n",
    "    .pipe((x: AIMessage) => x?.tool_calls?.[0]?.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { HumanMessage } from '@langchain/core/messages'\n",
    "\n",
    "await supervisorChain.invoke({\n",
    "    messages: [\n",
    "        new HumanMessage({\n",
    "            content: 'write a report on birds',\n",
    "        })\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { RunnableConfig } from '@langchain/core/runnables'\n",
    "import { createReactAgent } from '@langchain/langgraph/prebuilt'\n",
    "import { SystemMessage } from '@langchain/core/messages'\n",
    "\n",
    "const researcherAgent = createReactAgent({\n",
    "    llm,\n",
    "    tools: [tavilyTool],\n",
    "    stateModifier: new SystemMessage(\"You are a web researcher. You may use the Tavily search engine to search the web for\" +\n",
    "    \" important information, so the Chart Generator in your team can make useful plots.\")\n",
    "})\n",
    "\n",
    "const researcherNode = async (\n",
    "    state: typeof AgentState.State,\n",
    "    config?: RunnableConfig,\n",
    ") => {\n",
    "    const result = await researcherAgent.invoke(state, config)\n",
    "    const lastMessage = result.messages[result.messages.length - 1]\n",
    "    return {\n",
    "        messages: [\n",
    "            new HumanMessage({\n",
    "                content: lastMessage.content,\n",
    "                name: 'Researcher',\n",
    "            })\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "const chartGenAgent = createReactAgent({\n",
    "    llm,\n",
    "    tools: [chartTool],\n",
    "    stateModifier: new SystemMessage(\"You excel at generating bar charts. Use the researcher's information to generate the charts.\\nIf you don't have necessary data to generate bar charts, you should ask supervisor for it\")\n",
    "})\n",
    "\n",
    "const chartGenNode = async (\n",
    "    state: typeof AgentState.State,\n",
    "    config?: RunnableConfig,\n",
    ") => {\n",
    "    const result = await chartGenAgent.invoke(state, config)\n",
    "    const lastMessage = result.messages[result.messages.length - 1]\n",
    "    return {\n",
    "        messages: [\n",
    "            new HumanMessage({\n",
    "                content: lastMessage.content,\n",
    "                name: 'ChartGenerator',\n",
    "            })\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { START, StateGraph } from '@langchain/langgraph'\n",
    "\n",
    "const workflow = new StateGraph(AgentState)\n",
    "    .addNode('researcher',researcherNode)\n",
    "    .addNode('chart_generator', chartGenNode)\n",
    "    .addNode('supervisor', supervisorChain)\n",
    "\n",
    "members.forEach(member => {\n",
    "    workflow.addEdge(member, 'supervisor')\n",
    "})\n",
    "\n",
    "workflow.addConditionalEdges(\n",
    "    'supervisor',\n",
    "    (x: typeof AgentState.State) => x.next,\n",
    ")\n",
    "\n",
    "workflow.addEdge(START, 'supervisor')\n",
    "\n",
    "const graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { printGraph } from './../../utils.mjs'\n",
    "\n",
    "await printGraph(graph.getGraph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let streamResults = graph.stream(\n",
    "    {\n",
    "        messages: [\n",
    "            new HumanMessage({\n",
    "                content: 'What were the 3 most popular tv shows in 2023?',\n",
    "            })\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        recursionLimit: 100,\n",
    "    }\n",
    ")\n",
    "\n",
    "for await (const output of await streamResults) {\n",
    "    if (!output?.__end__) {\n",
    "        console.log(output)\n",
    "        console.log('----')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamResults = graph.stream(\n",
    "    {\n",
    "        messages: [\n",
    "            new HumanMessage({\n",
    "                content: 'Generate a bar chart of the US GDP growth from 2021-2023',\n",
    "            }),\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        recursionLimit: 150,\n",
    "    }\n",
    ")\n",
    "\n",
    "for await (const output of await streamResults) {\n",
    "    if (!output?.__end__) {\n",
    "        console.log(output)\n",
    "        console.log('----')\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
